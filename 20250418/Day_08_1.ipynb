{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJlSQMlwh33Z",
        "outputId": "6296c6cb-5597-4c60-c715-7097c5536d18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 18 15:55:06 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Write CUDA code to a file\n",
        "code = r'''\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <algorithm>\n",
        "#include <time.h>\n",
        "\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "__device__ __forceinline__ float get__value(const float* data, int index, int n)\n",
        "{\n",
        "    if(index < n)\n",
        "    {\n",
        "        return data[index];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        return 0.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void reduce_kernel(const float* data, float* result, int n)\n",
        "{\n",
        "    int d_i = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "\n",
        "    result[d_i] = get__value(data, 2*d_i, n) + get__value(data, 2*d_i + 1, n);\n",
        "\n",
        "    if (d_i == 0 && n % 2 != 0)\n",
        "    {\n",
        "        result[d_i] += data[n-1];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "    int n = 10000000;\n",
        "\n",
        "\n",
        "    float* data_h   = (float*)calloc(n, sizeof(float));\n",
        "\n",
        "    srand(42);\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        data_h[i] = float(rand())/float(RAND_MAX + 1.0);\n",
        "    }\n",
        "\n",
        "    float result_h = 0.0;\n",
        "\n",
        "    float* data_d;\n",
        "    cudaMalloc((void**)&data_d, n*sizeof(float));\n",
        "    cudaMemcpy(data_d, data_h, n*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = BLOCK_SIZE;\n",
        "    int numBlocks = n/2/BLOCK_SIZE + 1;\n",
        "\n",
        "    float* result1_d;\n",
        "    float* result2_d;\n",
        "    cudaMalloc((void**)&result1_d, n*sizeof(float));\n",
        "    cudaMalloc((void**)&result2_d, n*sizeof(float));\n",
        "\n",
        "    reduce_kernel<<<numBlocks, threadsPerBlock>>>(data_d, result1_d, n);\n",
        "    for (int n_c = n/2; n_c > 1; n_c = n_c/2)\n",
        "    {\n",
        "        int n_c_b = n_c/2/BLOCK_SIZE + 1;\n",
        "        reduce_kernel<<<n_c_b, threadsPerBlock>>>(result1_d, result2_d, n);\n",
        "        std::swap(result1_d, result2_d);\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(&result_h, result1_d, 1*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    free(data_h);\n",
        "    cudaFree(data_d);\n",
        "    cudaFree(result1_d);\n",
        "    cudaFree(result2_d);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "'''\n",
        "\n",
        "# Step 2: Save to file\n",
        "with open('vec_add.cu', 'w') as f:\n",
        "    f.write(code)\n",
        "\n",
        "# Step 3: Compile using nvcc\n",
        "# Ref: https://stackoverflow.com/questions/73361454/i-am-getting-zeros-as-a-result-of-vector-additon-in-cuda-and-no-errors\n",
        "!nvcc -arch=sm_75 vec_add.cu -o vec_add\n",
        "\n",
        "# Step 4: Run the binary\n",
        "!./vec_add\n"
      ],
      "metadata": {
        "id": "WosNuob-1Ae-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./vec_add --profile-from-start off"
      ],
      "metadata": {
        "id": "93MTzCF-ncNo",
        "outputId": "d6190f98-3900-470b-adee-2b971e53a45a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==2761== NVPROF is profiling process 2761, command: ./vec_add --profile-from-start off\n",
            "==2761== Profiling application: ./vec_add --profile-from-start off\n",
            "==2761== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   94.49%  8.8481ms         1  8.8481ms  8.8481ms  8.8481ms  [CUDA memcpy HtoD]\n",
            "                    5.49%  513.85us        23  22.341us  2.6550us  228.96us  reduce_kernel(float const *, float*, int)\n",
            "                    0.02%  2.0810us         1  2.0810us  2.0810us  2.0810us  [CUDA memcpy DtoH]\n",
            "      API calls:   93.52%  174.96ms         3  58.322ms  88.880us  174.74ms  cudaMalloc\n",
            "                    5.07%  9.4925ms         2  4.7463ms  464.63us  9.0279ms  cudaMemcpy\n",
            "                    1.23%  2.2922ms         3  764.08us  128.88us  1.1023ms  cudaFree\n",
            "                    0.11%  196.78us        23  8.5550us  3.0730us  114.33us  cudaLaunchKernel\n",
            "                    0.07%  125.07us       114  1.0970us     107ns  51.057us  cuDeviceGetAttribute\n",
            "                    0.01%  11.559us         1  11.559us  11.559us  11.559us  cuDeviceGetName\n",
            "                    0.00%  5.0450us         1  5.0450us  5.0450us  5.0450us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.1310us         3     377ns     129ns     777ns  cuDeviceGetCount\n",
            "                    0.00%     786ns         2     393ns     129ns     657ns  cuDeviceGet\n",
            "                    0.00%     454ns         1     454ns     454ns     454ns  cuModuleGetLoadingMode\n",
            "                    0.00%     397ns         1     397ns     397ns     397ns  cuDeviceTotalMem\n",
            "                    0.00%     242ns         1     242ns     242ns     242ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sYfRvW2png-n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}